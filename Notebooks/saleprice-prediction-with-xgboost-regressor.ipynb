{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from mlflow.tracking import MlflowClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"https://66e509f05a9319f04690f279.bm-east.lab.poridhi.io/proxy/5000/\")  # Replace with your MLflow server URI\n",
    "mlflow.set_experiment(\"House Price Prediction lab 10\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./house-prices-advanced-regression-techniques/train.csv')\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.isnull().sum()\n",
    "train_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(['Alley', 'PoolQC', 'Fence', 'MiscFeature', 'Id', 'GarageYrBlt'], axis=1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['LotFrontage']=train_data['LotFrontage'].fillna(train_data['LotFrontage'].mode()[0])\n",
    "train_data['BsmtCond']=train_data['BsmtCond'].fillna(train_data['BsmtCond'].mode()[0])\n",
    "train_data['BsmtQual']=train_data['BsmtQual'].fillna(train_data['BsmtQual'].mode()[0])\n",
    "train_data['FireplaceQu']=train_data['FireplaceQu'].fillna(train_data['FireplaceQu'].mode()[0])\n",
    "train_data['GarageType']=train_data['GarageType'].fillna(train_data['GarageType'].mode()[0])\n",
    "train_data['GarageFinish']=train_data['GarageFinish'].fillna(train_data['GarageFinish'].mode()[0])\n",
    "train_data['GarageQual']=train_data['GarageQual'].fillna(train_data['GarageQual'].mode()[0])\n",
    "train_data['GarageCond']=train_data['GarageCond'].fillna(train_data['GarageCond'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.isnull().sum().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(train_data.isnull(),yticklabels=False,cbar=False,cmap='coolwarm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['MasVnrType']=train_data['MasVnrType'].fillna(train_data['MasVnrType'].mode()[0])\n",
    "train_data['MasVnrArea']=train_data['MasVnrArea'].fillna(train_data['MasVnrArea'].mode()[0])\n",
    "train_data['BsmtExposure']=train_data['BsmtExposure'].fillna(train_data['BsmtExposure'].mode()[0])\n",
    "train_data['BsmtFinType2']=train_data['BsmtFinType2'].fillna(train_data['BsmtFinType2'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_data.isnull(), yticklabels=False, cbar=False, cmap='YlGnBu')\n",
    "train_data.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./house-prices-advanced-regression-techniques/test.csv')\n",
    "test_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.isnull().sum()\n",
    "test_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.drop(['Alley', 'PoolQC', 'Fence', 'MiscFeature', 'Id', 'GarageYrBlt'], axis=1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['LotFrontage']=test_data['LotFrontage'].fillna(test_data['LotFrontage'].mode()[0])\n",
    "test_data['BsmtCond']=test_data['BsmtCond'].fillna(test_data['BsmtCond'].mode()[0])\n",
    "test_data['BsmtQual']=test_data['BsmtQual'].fillna(test_data['BsmtQual'].mode()[0])\n",
    "test_data['FireplaceQu']=test_data['FireplaceQu'].fillna(test_data['FireplaceQu'].mode()[0])\n",
    "test_data['GarageType']=test_data['GarageType'].fillna(test_data['GarageType'].mode()[0])\n",
    "test_data['GarageFinish']=test_data['GarageFinish'].fillna(test_data['GarageFinish'].mode()[0])\n",
    "test_data['GarageQual']=test_data['GarageQual'].fillna(test_data['GarageQual'].mode()[0])\n",
    "test_data['GarageCond']=test_data['GarageCond'].fillna(test_data['GarageCond'].mode()[0])\n",
    "test_data['MasVnrType']=test_data['MasVnrType'].fillna(test_data['MasVnrType'].mode()[0])\n",
    "test_data['MasVnrArea']=test_data['MasVnrArea'].fillna(test_data['MasVnrArea'].mode()[0])\n",
    "test_data['BsmtExposure']=test_data['BsmtExposure'].fillna(test_data['BsmtExposure'].mode()[0])\n",
    "test_data['BsmtFinType2']=test_data['BsmtFinType2'].fillna(test_data['BsmtFinType2'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.loc[:, test_data.isnull().any()].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Utilities']=test_data['Utilities'].fillna(test_data['Utilities'].mode()[0])\n",
    "test_data['Exterior1st']=test_data['Exterior1st'].fillna(test_data['Exterior1st'].mode()[0])\n",
    "test_data['Exterior2nd']=test_data['Exterior2nd'].fillna(test_data['Exterior2nd'].mode()[0])\n",
    "test_data['BsmtFinType1']=test_data['BsmtFinType1'].fillna(test_data['BsmtFinType1'].mode()[0])\n",
    "test_data['BsmtFinSF1']=test_data['BsmtFinSF1'].fillna(test_data['BsmtFinSF1'].mean())\n",
    "test_data['BsmtFinSF2']=test_data['BsmtFinSF2'].fillna(test_data['BsmtFinSF2'].mean())\n",
    "test_data['BsmtUnfSF']=test_data['BsmtUnfSF'].fillna(test_data['BsmtUnfSF'].mean())\n",
    "test_data['TotalBsmtSF']=test_data['TotalBsmtSF'].fillna(test_data['TotalBsmtSF'].mean())\n",
    "test_data['BsmtFullBath']=test_data['BsmtFullBath'].fillna(test_data['BsmtFullBath'].mode()[0])\n",
    "test_data['BsmtHalfBath']=test_data['BsmtHalfBath'].fillna(test_data['BsmtHalfBath'].mode()[0])\n",
    "test_data['KitchenQual']=test_data['KitchenQual'].fillna(test_data['KitchenQual'].mode()[0])\n",
    "test_data['Functional']=test_data['Functional'].fillna(test_data['Functional'].mode()[0])\n",
    "test_data['GarageCars']=test_data['GarageCars'].fillna(test_data['GarageCars'].mean())\n",
    "test_data['GarageArea']=test_data['GarageArea'].fillna(test_data['GarageArea'].mean())\n",
    "test_data['SaleType']=test_data['SaleType'].fillna(test_data['SaleType'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood',\n",
    "         'Condition2','BldgType','Condition1','HouseStyle','SaleType',\n",
    "        'SaleCondition','ExterCond',\n",
    "         'ExterQual','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n",
    "        'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Heating','HeatingQC',\n",
    "         'CentralAir',\n",
    "         'Electrical','KitchenQual','Functional',\n",
    "         'FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_onehot_multcols(multcolumns):\n",
    "    data_final=final_data\n",
    "    i=0\n",
    "    for fields in multcolumns:\n",
    "        \n",
    "        print(fields)\n",
    "        df1=pd.get_dummies(final_data[fields],drop_first=True)\n",
    "        \n",
    "        final_data.drop([fields],axis=1,inplace=True)\n",
    "        if i==0:\n",
    "            data_final=df1.copy()\n",
    "        else:\n",
    "            \n",
    "            data_final=pd.concat([data_final,df1],axis=1)\n",
    "        i=i+1\n",
    "       \n",
    "        \n",
    "    data_final=pd.concat([final_data,data_final],axis=1)\n",
    "        \n",
    "    return data_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2 = train_data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=pd.concat([train_data,test_data],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['SalePrice']\n",
    "final_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=category_onehot_multcols(columns)\n",
    "final_data = final_data.loc[:,~final_data.columns.duplicated()]\n",
    "final_data.isnull().sum().sum()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_columns = ['Min1', 'Min2', 'Typ', 'Attchd', 'Basment', 'BuiltIn', 'CarPort', 'Detchd', 'RFn', 'P']\n",
    "for col in boolean_columns:\n",
    "    final_data[col] = final_data[col].astype(int)\n",
    "    final_data[col] = final_data[col].astype(int)\n",
    "\n",
    "final_data.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = final_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "final_data[numeric_columns] = final_data[numeric_columns].astype(float)\n",
    "\n",
    "final_data.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values_before = final_data.isnull().sum().sum()\n",
    "null_columns = final_data.columns[final_data.isnull().any()].tolist()\n",
    "print(\"Columns with null values:\")\n",
    "for col in null_columns:\n",
    "    print(f\"{col}: {final_data[col].isnull().sum()} nulls\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in null_columns:\n",
    "    if final_data[col].dtype == 'object':\n",
    "        # For categorical columns, fill with mode\n",
    "        final_data[col] = final_data[col].fillna(final_data[col].mode()[0])\n",
    "    else:\n",
    "        # For numerical columns, fill with mean\n",
    "        final_data[col] = final_data[col].fillna(final_data[col].mean())\n",
    "\n",
    "# Verify all nulls are handled\n",
    "print(\"Remaining null values:\", final_data.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"data_preprocessing\") as run:\n",
    "    # Log dataset info\n",
    "    mlflow.log_param(\"dataset_size\", len(final_data))\n",
    "    mlflow.log_param(\"num_features\", final_data.shape[1])\n",
    "    \n",
    "    # Log preprocessing steps\n",
    "    preprocessing_steps = {\n",
    "        \"dropped_columns\": ['Alley', 'PoolQC', 'Fence', 'MiscFeature', 'Id', 'GarageYrBlt'],\n",
    "        \"filled_null_columns\": [\"LotFrontage\", \"BsmtCond\", \"BsmtQual\", \"FireplaceQu\", \n",
    "                              \"GarageType\", \"GarageFinish\", \"GarageQual\", \"GarageCond\"]\n",
    "    }\n",
    "    mlflow.log_dict(preprocessing_steps, \"preprocessing_steps.json\")\n",
    "    \n",
    "    # Log data quality metrics\n",
    "    data_quality_metrics = {\n",
    "        \"null_values_before\": null_values_before,\n",
    "        \"null_values_after\": final_data.isnull().sum().sum()\n",
    "    }\n",
    "    mlflow.log_metrics(data_quality_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=final_data.iloc[:1422,:]\n",
    "data_test=final_data.iloc[1422:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=data_train.drop(['SalePrice'],axis=1)\n",
    "y_train=data_train['SalePrice']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "regressor=xgboost.XGBRegressor()\n",
    "\n",
    "booster=['gbtree','gblinear']\n",
    "base_score=[0.25,0.5,0.75,1]\n",
    "\n",
    "n_estimators = [100, 500, 900, 1100, 1500]\n",
    "max_depth = [2, 3, 5, 10, 15]\n",
    "booster=['gbtree','gblinear']\n",
    "learning_rate=[0.05,0.1,0.15,0.20]\n",
    "min_child_weight=[1,2,3,4]\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'learning_rate':learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "    'booster':booster,\n",
    "    'base_score':base_score\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_cv = RandomizedSearchCV(estimator=regressor,\n",
    "            param_distributions=hyperparameter_grid,\n",
    "            cv=5, n_iter=50,\n",
    "            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n",
    "            verbose = 5, \n",
    "            return_train_score = True,\n",
    "            random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    predictions = model.predict(X)\n",
    "    mse = mean_squared_error(y, predictions)\n",
    "    mae = mean_absolute_error(y, predictions)\n",
    "    r2 = r2_score(y, predictions)\n",
    "    return {\"mse\": mse, \"mae\": mae, \"r2\": r2, \"rmse\": np.sqrt(mse)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"model_training\") as run:\n",
    "    # Log hyperparameter search space\n",
    "    mlflow.log_dict(hyperparameter_grid, \"hyperparameter_grid.json\")\n",
    "    \n",
    "    # Perform RandomizedSearchCV\n",
    "    random_cv.fit(X_train, y_train)\n",
    "    \n",
    "    # Log best parameters\n",
    "    mlflow.log_params(random_cv.best_params_)\n",
    "    \n",
    "    # Log cross-validation results\n",
    "    cv_results = {\n",
    "        \"mean_test_score\": random_cv.cv_results_['mean_test_score'],\n",
    "        \"std_test_score\": random_cv.cv_results_['std_test_score'],\n",
    "        \"mean_train_score\": random_cv.cv_results_['mean_train_score'],\n",
    "        \"std_train_score\": random_cv.cv_results_['std_train_score']\n",
    "    }\n",
    "    mlflow.log_dict(cv_results, \"cv_results.json\")\n",
    "    \n",
    "    # Log best model metrics\n",
    "    best_model = random_cv.best_estimator_\n",
    "    train_metrics = evaluate_model(best_model, X_train, y_train)\n",
    "    mlflow.log_metrics(train_metrics)\n",
    "    \n",
    "    # Log feature importance plot\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X_train.columns,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(feature_importance['feature'][:10], feature_importance['importance'][:10])\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title('Top 10 Feature Importance')\n",
    "    plt.tight_layout()\n",
    "    mlflow.log_figure(plt.gcf(), \"feature_importance.png\")\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.xgboost.log_model(best_model, \"model\",\n",
    "                            registered_model_name=\"house_price_prediction_model\")\n",
    "\n",
    "    # Print best score and parameters\n",
    "    print(f\"Best score: {random_cv.best_score_}\")\n",
    "    print(f\"Best parameters: {random_cv.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "best_model = random_cv.best_estimator_\n",
    "filename = 'finalized_model.pkl'\n",
    "pickle.dump(best_model, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "with mlflow.start_run(run_name=\"model_prediction\") as run:\n",
    "    # Make predictions\n",
    "    y_pred = best_model.predict(data_test)\n",
    "    \n",
    "    # Log prediction statistics\n",
    "    prediction_stats = {\n",
    "        \"mean_predicted_price\": float(np.mean(y_pred)),\n",
    "        \"median_predicted_price\": float(np.median(y_pred)),\n",
    "        \"std_predicted_price\": float(np.std(y_pred)),\n",
    "        \"min_predicted_price\": float(np.min(y_pred)),\n",
    "        \"max_predicted_price\": float(np.max(y_pred))\n",
    "    }\n",
    "    mlflow.log_metrics(prediction_stats)\n",
    "    \n",
    "    # Create and save predictions to a CSV file\n",
    "    prediction_df = pd.DataFrame({\n",
    "        'predicted_price': y_pred\n",
    "    })\n",
    "    \n",
    "    # Save predictions locally\n",
    "    predictions_path = \"predictions.csv\"\n",
    "    prediction_df.to_csv(predictions_path, index=False)\n",
    "    \n",
    "    # Log the predictions file\n",
    "    mlflow.log_artifact(predictions_path)\n",
    "    \n",
    "    # Create and log a histogram of predictions\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(y_pred, bins=50)\n",
    "    plt.title('Distribution of Predicted House Prices')\n",
    "    plt.xlabel('Predicted Price')\n",
    "    plt.ylabel('Frequency')\n",
    "    mlflow.log_figure(plt.gcf(), \"prediction_distribution.png\")\n",
    "    \n",
    "    # Log model version and status\n",
    "    client = MlflowClient()\n",
    "    try:\n",
    "        model_version = client.get_latest_versions(\"house_price_prediction_model\", stages=[\"None\"])[0]\n",
    "        client.transition_model_version_stage(\n",
    "            name=\"house_price_prediction_model\",\n",
    "            version=model_version.version,\n",
    "            stage=\"Production\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error updating model version: {str(e)}\")\n",
    "    \n",
    "    # Clean up\n",
    "    plt.close()\n",
    "    if os.path.exists(predictions_path):\n",
    "        os.remove(predictions_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_runs(experiment_name=\"House Price Prediction\", top_n=5):\n",
    "    \"\"\"Compare different runs and their metrics\"\"\"\n",
    "    \n",
    "    # Start a new MLflow run to track this comparison process\n",
    "    with mlflow.start_run(run_name=\"model_comparison\"):\n",
    "        client = MlflowClient()\n",
    "        experiment = client.get_experiment_by_name(experiment_name)\n",
    "        \n",
    "        # Search for runs based on R2 score in descending order\n",
    "        runs = client.search_runs(\n",
    "            experiment_ids=[experiment.experiment_id],\n",
    "            order_by=[\"metrics.r2 DESC\"]\n",
    "        )\n",
    "        \n",
    "        # Create a DataFrame to store the top N runs' performance and parameters\n",
    "        comparison_df = pd.DataFrame([\n",
    "            {\n",
    "                'run_id': run.info.run_id,\n",
    "                'r2_score': run.data.metrics.get('r2', None),\n",
    "                'rmse': run.data.metrics.get('rmse', None),\n",
    "                'mae': run.data.metrics.get('mae', None),\n",
    "                'parameters': run.data.params\n",
    "            }\n",
    "            for run in runs[:top_n]\n",
    "        ])\n",
    "        \n",
    "        # Log comparison DataFrame as an artifact (optional)\n",
    "        comparison_df_path = \"run_comparison.csv\"\n",
    "        comparison_df.to_csv(comparison_df_path, index=False)\n",
    "        mlflow.log_artifact(comparison_df_path)\n",
    "\n",
    "        # Optionally, log the best performing run's metrics for tracking\n",
    "        best_run = runs[0]\n",
    "        best_run_metrics = {\n",
    "            \"best_r2_score\": best_run.data.metrics.get('r2', None),\n",
    "            \"best_rmse\": best_run.data.metrics.get('rmse', None),\n",
    "            \"best_mae\": best_run.data.metrics.get('mae', None)\n",
    "        }\n",
    "        mlflow.log_metrics(best_run_metrics)\n",
    "\n",
    "        # Print and return the comparison dataframe\n",
    "        print(\"Best performing runs:\")\n",
    "        print(comparison_df)\n",
    "\n",
    "    return comparison_df\n",
    "\n",
    "# Example usage after model training\n",
    "best_runs = compare_runs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_best_model(experiment_name=\"House Price Prediction\"):\n",
    "    \"\"\"Register the best performing model to the model registry\"\"\"\n",
    "    client = MlflowClient()\n",
    "    experiment = client.get_experiment_by_name(experiment_name)\n",
    "    best_run = client.search_runs(\n",
    "        experiment_ids=[experiment.experiment_id],\n",
    "        order_by=[\"metrics.r2 DESC\"]\n",
    "    )[0]\n",
    "    \n",
    "    # Register the model from the best run\n",
    "    model_uri = f\"runs:/{best_run.info.run_id}/model\"\n",
    "    mv = mlflow.register_model(model_uri, \"house_price_prediction_model\")\n",
    "    \n",
    "    # Transition the model to production\n",
    "    client.transition_model_version_stage(\n",
    "        name=\"house_price_prediction_model\",\n",
    "        version=mv.version,\n",
    "        stage=\"Production\"\n",
    "    )\n",
    "    \n",
    "    return mv\n",
    "\n",
    "# Add after model training\n",
    "best_model_version = register_best_model()\n",
    "print(f\"Registered model version: {best_model_version.version}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
